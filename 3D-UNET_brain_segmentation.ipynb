{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled25.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPfwIsS6pOJscPGLSMOjZgB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Article_implementation/blob/main/3D-UNET_brain_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Brain_segmentation_pytorch 3D-UNET**\n",
        "\n",
        "CTの複数画像を立体的にsegmentationする\n",
        "\n",
        "GitHub: hhttps://github.com/mateuszbuda/brain-segmentation-pytorch\n",
        "\n",
        "WebPage: https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-model-building-6ab09d6a0862\n"
      ],
      "metadata": {
        "id": "MTShhTbs_oB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mateuszbuda/brain-segmentation-pytorch.git\n",
        "\n",
        "#作業フォルダを移動\n",
        "%cd brain-segmentation-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPPewOUcW1Qo",
        "outputId": "e9518ff0-c24b-4994-9638-d8f11b2c53db"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'brain-segmentation-pytorch' already exists and is not an empty directory.\n",
            "/content/brain-segmentation-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kaggle_3M datasetのダウンロード\n",
        "\n",
        "まずKaggleに登録してAPIの使用許可を申請する必要あり。詳細は下記を参考に。\n",
        "\n",
        "https://www.currypurin.com/entry/2018/kaggle-api"
      ],
      "metadata": {
        "id": "zh-_NsecRKXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# kaggle ライブラリのインストール\n",
        "!pip install kaggle\n",
        "\n",
        "# 一時フォルダに .kaggleフォルダを作成\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "# MyDrive の kaggle.json　(permissionファイル) を一時フォルダ内の .kaggleフォルダにコピー\n",
        "!cp /content/drive/MyDrive/Kaggle/kaggle.json ~/.kaggle/\n",
        "\n",
        "# アクセス権限の設定\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "# zipファイルのダウンロード\n",
        "!kaggle datasets download -d mateuszbuda/lgg-mri-segmentation\n",
        "#!kaggle competitions download -c rsna-2022-cervical-spine-fracture-detection -p /content/drive/MyDrive/Kaggle\n",
        "# 解凍\n",
        "!unzip ./lgg-mri-segmentation.zip -d ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qItwihSrRCuO",
        "outputId": "85fb707d-e0a1-4696-c40e-0099b7740370"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "lgg-mri-segmentation.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  ./lgg-mri-segmentation.zip\n",
            "replace ./kaggle_3m/README.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ここから"
      ],
      "metadata": {
        "id": "Yd4x2Yg3TKt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Requirementsからモジュールをインストール\n",
        "#※バージョンがconflictしまくるのでバージョン指定なし\n",
        "#medpy以外はすでに入っている\n",
        "\n",
        "modules = \"\"\"\n",
        "numpy\n",
        "tensorflow\n",
        "scikit-learn\n",
        "scikit-image\n",
        "imageio\n",
        "medpy\n",
        "Pillow\n",
        "scipy\n",
        "pandas\n",
        "tqdm\n",
        "\"\"\"\n",
        "\n",
        "with open(\"requirements.txt\", mode=\"w\") as f:\n",
        "    f.write(modules)\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
        "from medpy.filter.binary import largest_connected_component\n",
        "from skimage.io import imsave\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from dataset import BrainSegmentationDataset as Dataset\n",
        "from unet import UNet\n",
        "from utils import dsc, gray2rgb, outline\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n"
      ],
      "metadata": {
        "id": "3Q1C07gvZFBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**interference**"
      ],
      "metadata": {
        "id": "kZRO0btlksID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_per_volume(\n",
        "    input_list, pred_list, true_list, patient_slice_index, patients\n",
        "):\n",
        "    volumes = {}\n",
        "    num_slices = np.bincount([p[0] for p in patient_slice_index]) #各要素が何個ずつあるかを数える\n",
        "    index = 0\n",
        "    for p in range(len(num_slices)):\n",
        "        volume_in = np.array(input_list[index : index + num_slices[p]])\n",
        "        volume_pred = np.round(\n",
        "            np.array(pred_list[index : index + num_slices[p]])\n",
        "        ).astype(int)\n",
        "        volume_pred = largest_connected_component(volume_pred)\n",
        "        volume_true = np.array(true_list[index : index + num_slices[p]])\n",
        "        volumes[patients[p]] = (volume_in, volume_pred, volume_true)\n",
        "        index += num_slices[p]\n",
        "    return volumes\n",
        "\n",
        "def dsc_distribution(volumes):\n",
        "    dsc_dict = {}\n",
        "    for p in volumes:\n",
        "        y_pred = volumes[p][1]\n",
        "        y_true = volumes[p][2]\n",
        "        dsc_dict[p] = dsc(y_pred, y_true, lcc=False)\n",
        "    return dsc_dict\n",
        "\n",
        "def plot_dsc(dsc_dist):\n",
        "    y_positions = np.arange(len(dsc_dist))\n",
        "    dsc_dist = sorted(dsc_dist.items(), key=lambda x: x[1])\n",
        "    values = [x[1] for x in dsc_dist]\n",
        "    labels = [x[0] for x in dsc_dist]\n",
        "    labels = [\"_\".join(l.split(\"_\")[1:-1]) for l in labels]\n",
        "    fig = plt.figure(figsize=(12, 8))\n",
        "    canvas = FigureCanvasAgg(fig)\n",
        "    plt.barh(y_positions, values, align=\"center\", color=\"skyblue\")\n",
        "    plt.yticks(y_positions, labels)\n",
        "    plt.xticks(np.arange(0.0, 1.0, 0.1))\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.gca().axvline(np.mean(values), color=\"tomato\", linewidth=2)\n",
        "    plt.gca().axvline(np.median(values), color=\"forestgreen\", linewidth=2)\n",
        "    plt.xlabel(\"Dice coefficient\", fontsize=\"x-large\")\n",
        "    plt.gca().xaxis.grid(color=\"silver\", alpha=0.5, linestyle=\"--\", linewidth=1)\n",
        "    plt.tight_layout()\n",
        "    canvas.draw()\n",
        "    plt.close()\n",
        "    s, (width, height) = canvas.print_to_buffer()\n",
        "    return np.fromstring(s, np.uint8).reshape((height, width, 4))\n",
        "\n",
        "def outline(image, mask, color):\n",
        "    mask = np.round(mask)\n",
        "    yy, xx = np.nonzero(mask)\n",
        "    for y, x in zip(yy, xx):\n",
        "        if 0.0 < np.mean(mask[max(0, y - 1) : y + 2, max(0, x - 1) : x + 2]) < 1.0:\n",
        "            image[max(0, y) : y + 1, max(0, x) : x + 1] = color\n",
        "    return image\n",
        "\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from skimage.io import imread\n",
        "from skimage.exposure import rescale_intensity\n",
        "from skimage.transform import resize\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from utils import crop_sample, pad_sample, resize_sample, normalize_volume\n",
        "\n",
        "\n",
        "# #dataset (datasetフォルダに入っているのでここに書く必要ないが、解説のために再定義)\n",
        "class BrainSegmentationDataset(Dataset):\n",
        "    \"\"\"Brain MRI dataset for FLAIR abnormality segmentation\"\"\"\n",
        "\n",
        "    in_channels = 3\n",
        "    out_channels = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        images_dir,\n",
        "        transform=None,\n",
        "        image_size=256,\n",
        "        subset=\"train\",\n",
        "        random_sampling=True,\n",
        "        validation_cases=10,\n",
        "        seed=42,\n",
        "    ):\n",
        "        assert subset in [\"all\", \"train\", \"validation\"] #all, train,validation以外のsubsetにするとエラーを出す\n",
        "\n",
        "        # read images\n",
        "        volumes = {}\n",
        "        masks = {}\n",
        "        print(\"reading {} images...\".format(subset))\n",
        "        for (dirpath, dirnames, filenames) in os.walk(images_dir): #dirpath: 親フォルダのパス、filenames: ファイルの名前\n",
        "            image_slices = []\n",
        "            mask_slices = []\n",
        "\n",
        "            for filename in sorted(\n",
        "                filter(lambda f: \".tif\" in f, filenames),  \n",
        "                key=lambda x: int(x.split(\".\")[-2].split(\"_\")[4]),\n",
        "            ): #tifがついているファイルを番号順にソートする\n",
        "                filepath = os.path.join(dirpath, filename)\n",
        "                if \"mask\" in filename: #maskがファイル名についているもの\n",
        "                    mask_slices.append(imread(filepath, as_gray=True))\n",
        "                else: #ついていないもの\n",
        "                    image_slices.append(imread(filepath))\n",
        "            if len(image_slices) > 0:\n",
        "                patient_id = dirpath.split(\"/\")[-1] #TCGA_HT_8018_19970411\n",
        "                volumes[patient_id] = np.array(image_slices[1:-1]) #volumes: マスクなし画像,RGB(最初と最後の1枚ずつを除外する（informationなどがある？？？？）)\n",
        "                masks[patient_id] = np.array(mask_slices[1:-1]) #masks: マスク画像, grayscale\n",
        "\n",
        "        self.patients = sorted(volumes) #patientsのリストをソート\n",
        "\n",
        "        # select cases to subset\n",
        "        if not subset == \"all\":\n",
        "            random.seed(seed)\n",
        "            validation_patients = random.sample(self.patients, k=validation_cases) #validation_casesで指定した分だけ無作為に抜き出す\n",
        "            if subset == \"validation\":\n",
        "                self.patients = validation_patients\n",
        "            else:\n",
        "                self.patients = sorted(\n",
        "                    list(set(self.patients).difference(validation_patients))\n",
        "                )\n",
        "\n",
        "        print(\"preprocessing {} volumes...\".format(subset))\n",
        "        \n",
        "        # create list of tuples (volume, mask)\n",
        "        self.volumes = [(volumes[k], masks[k]) for k in self.patients]\n",
        "\n",
        "        print(f\"volumes: {volumes[self.patients[2]].shape}\") #(26,256,256,3) --> 枚数、縦、横、RGB\n",
        "        print(f\"masks: {volumes[self.patients[2]].shape}\") #(26,256,256,3)\n",
        "\n",
        "        print(\"cropping {} volumes...\".format(subset))\n",
        "        # crop to smallest enclosing volume ...何をしているのかいまいちよくわからない...\n",
        "        self.volumes = [crop_sample(v) for v in self.volumes]\n",
        "\n",
        "        print(\"padding {} volumes...\".format(subset))\n",
        "        # pad to square  横長の画像を正方形に\n",
        "        self.volumes = [pad_sample(v) for v in self.volumes]\n",
        "\n",
        "        print(\"resizing {} volumes...\".format(subset))\n",
        "        # resize\n",
        "        self.volumes = [resize_sample(v, size=image_size) for v in self.volumes]\n",
        "\n",
        "        print(\"normalizing {} volumes...\".format(subset))\n",
        "        # normalize channel-wise\n",
        "        self.volumes = [(normalize_volume(v), m) for v, m in self.volumes]  #v: volume, m: mask\n",
        "\n",
        "        # probabilities for sampling slices based on masks\n",
        "        self.slice_weights = [m.sum(axis=-1).sum(axis=-1) for v, m in self.volumes]\n",
        "        self.slice_weights = [\n",
        "            (s + (s.sum() * 0.1 / len(s))) / (s.sum() * 1.1) for s in self.slice_weights\n",
        "        ]\n",
        "\n",
        "        # add channel dimension to masks\n",
        "        self.volumes = [(v, m[..., np.newaxis]) for (v, m) in self.volumes]\n",
        "\n",
        "        print(\"done creating {} dataset\".format(subset))\n",
        "\n",
        "        # create global index for patient and slice (idx -> (p_idx, s_idx))\n",
        "        num_slices = [v.shape[0] for v, m in self.volumes]\n",
        "        self.patient_slice_index = list(\n",
        "            zip(\n",
        "                sum([[i] * num_slices[i] for i in range(len(num_slices))], []),\n",
        "                sum([list(range(x)) for x in num_slices], []),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.random_sampling = random_sampling\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_slice_index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        patient = self.patient_slice_index[idx][0]\n",
        "        slice_n = self.patient_slice_index[idx][1]\n",
        "\n",
        "        if self.random_sampling:\n",
        "            patient = np.random.randint(len(self.volumes))\n",
        "            slice_n = np.random.choice(\n",
        "                range(self.volumes[patient][0].shape[0]), p=self.slice_weights[patient]\n",
        "            )\n",
        "\n",
        "        v, m = self.volumes[patient]\n",
        "        image = v[slice_n]\n",
        "        mask = m[slice_n]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image, mask = self.transform((image, mask))\n",
        "\n",
        "        # fix dimensions (C, H, W)\n",
        "        image = image.transpose(2, 0, 1)\n",
        "        mask = mask.transpose(2, 0, 1)\n",
        "\n",
        "        image_tensor = torch.from_numpy(image.astype(np.float32))\n",
        "        mask_tensor = torch.from_numpy(mask.astype(np.float32))\n",
        "\n",
        "        # return tensors\n",
        "        return image_tensor, mask_tensor\n",
        "\n",
        "\n",
        "#以下utilisより抜粋（utilisよりimportされているのでここで定義しなくてもOK）\n",
        "def crop_sample(x):\n",
        "    volume, mask = x\n",
        "    volume[volume < np.max(volume) * 0.1] = 0 #最高densityの0.1倍未満のものはゼロに切り捨てる\n",
        "    z_projection = np.max(np.max(np.max(volume, axis=-1), axis=-1), axis=-1)\n",
        "    z_nonzero = np.nonzero(z_projection)\n",
        "    z_min = np.min(z_nonzero)\n",
        "    z_max = np.max(z_nonzero) + 1\n",
        "    y_projection = np.max(np.max(np.max(volume, axis=0), axis=-1), axis=-1)\n",
        "    y_nonzero = np.nonzero(y_projection)\n",
        "    y_min = np.min(y_nonzero)\n",
        "    y_max = np.max(y_nonzero) + 1\n",
        "    x_projection = np.max(np.max(np.max(volume, axis=0), axis=0), axis=-1)\n",
        "    x_nonzero = np.nonzero(x_projection)\n",
        "    x_min = np.min(x_nonzero)\n",
        "    x_max = np.max(x_nonzero) + 1\n",
        "    return (\n",
        "        volume[z_min:z_max, y_min:y_max, x_min:x_max],\n",
        "        mask[z_min:z_max, y_min:y_max, x_min:x_max],\n",
        "    )\n",
        "\n",
        "def pad_sample(x): #横長の画像を正方形にする\n",
        "    volume, mask = x\n",
        "    a = volume.shape[1]\n",
        "    b = volume.shape[2]\n",
        "    if a == b:\n",
        "        return volume, mask\n",
        "    diff = (max(a, b) - min(a, b)) / 2.0\n",
        "    if a > b:\n",
        "        padding = ((0, 0), (0, 0), (int(np.floor(diff)), int(np.ceil(diff))))\n",
        "    else:\n",
        "        padding = ((0, 0), (int(np.floor(diff)), int(np.ceil(diff))), (0, 0))\n",
        "    mask = np.pad(mask, padding, mode=\"constant\", constant_values=0)\n",
        "    padding = padding + ((0, 0),)\n",
        "    volume = np.pad(volume, padding, mode=\"constant\", constant_values=0)\n",
        "    return volume, mask\n",
        "\n",
        "def normalize_volume(volume):\n",
        "    p10 = np.percentile(volume, 10)\n",
        "    p99 = np.percentile(volume, 99)\n",
        "    volume = rescale_intensity(volume, in_range=(p10, p99)) #skimageを用いてintensityの上下を切ってnormalizeする\n",
        "    m = np.mean(volume, axis=(0, 1, 2))\n",
        "    s = np.std(volume, axis=(0, 1, 2))\n",
        "    volume = (volume - m) / s\n",
        "    return volume\n",
        "\n",
        "def resize_sample(x, size=256): #skimage.transform.resizeを用いてsize=256にリサイズ）\n",
        "    volume, mask = x\n",
        "    v_shape = volume.shape\n",
        "    out_shape = (v_shape[0], size, size)\n",
        "    mask = resize(\n",
        "        mask,\n",
        "        output_shape=out_shape,\n",
        "        order=0,\n",
        "        mode=\"constant\",\n",
        "        cval=0,\n",
        "        anti_aliasing=False,\n",
        "    ) #order=0: nearest neighbor\n",
        "    out_shape = out_shape + (v_shape[3],)\n",
        "    volume = resize(\n",
        "        volume,\n",
        "        output_shape=out_shape,\n",
        "        order=2,\n",
        "        mode=\"constant\",\n",
        "        cval=0,\n",
        "        anti_aliasing=False,\n",
        "    ) #order=2: bi-quadratic\n",
        "    return volume, mask\n"
      ],
      "metadata": {
        "id": "Unh_DrpaikGH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#これでインポートしてもOK\n",
        "#from dataset import BrainSegmentationDataset as Dataset\n",
        "\n",
        "\n",
        "#############################\n",
        "weights_dir = \"./weights/unet.pt\" #weightの保存先\n",
        "#############################\n",
        "\n",
        "#predictionsフォルダ作成\n",
        "os.makedirs(\"./predictions\", exist_ok=True)\n",
        "\n",
        "#deviceを定義\n",
        "device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda:0\")\n",
        "\n",
        "#データセットとデータローダー\n",
        "dataset = BrainSegmentationDataset(\n",
        "    images_dir=\"./lgg-mri-segmentation/kaggle_3m\", #kaggle dataset使用\n",
        "    subset=\"validation\",\n",
        "    image_size=256,\n",
        "    random_sampling=False,\n",
        ")\n",
        "loader = DataLoader(\n",
        "    dataset, batch_size=32, drop_last=False, num_workers=1\n",
        ")\n",
        "\n",
        "with torch.set_grad_enabled(False):\n",
        "    unet = UNet(in_channels=BrainSegmentationDataset.in_channels, out_channels=BrainSegmentationDataset.out_channels)\n",
        "    \n",
        "    #モデルのweightをロード\n",
        "    state_dict = torch.load(weights_dir, map_location=device)\n",
        "    unet.load_state_dict(state_dict)\n",
        "\n",
        "    unet.eval()\n",
        "    unet.to(device)\n",
        "\n",
        "    input_list = []\n",
        "    pred_list = []\n",
        "    true_list = []\n",
        "\n",
        "    for i, data in tqdm(enumerate(loader)):\n",
        "        x, y_true = data\n",
        "        x, y_true = x.to(device), y_true.to(device)\n",
        "\n",
        "        y_pred = unet(x)\n",
        "        y_pred_np = y_pred.detach().cpu().numpy()\n",
        "        pred_list.extend([y_pred_np[s] for s in range(y_pred_np.shape[0])])\n",
        "\n",
        "        y_true_np = y_true.detach().cpu().numpy()\n",
        "        true_list.extend([y_true_np[s] for s in range(y_true_np.shape[0])])\n",
        "\n",
        "        x_np = x.detach().cpu().numpy()\n",
        "        input_list.extend([x_np[s] for s in range(x_np.shape[0])])\n",
        "\n",
        "    volumes = postprocess_per_volume(\n",
        "        input_list,\n",
        "        pred_list,\n",
        "        true_list,\n",
        "        loader.dataset.patient_slice_index,\n",
        "        loader.dataset.patients,\n",
        "    )\n",
        "\n",
        "    dsc_dist = dsc_distribution(volumes)\n",
        "\n",
        "    dsc_dist_plot = plot_dsc(dsc_dist)\n",
        "    imsave(\"./dsc.png\", dsc_dist_plot)\n",
        "\n",
        "    for p in volumes:\n",
        "        x = volumes[p][0]\n",
        "        y_pred = volumes[p][1]\n",
        "        y_true = volumes[p][2]\n",
        "        for s in range(x.shape[0]):\n",
        "            image = gray2rgb(x[s, 1])  # channel 1 is for FLAIR\n",
        "            image = outline(image, y_pred[s, 0], color=[255, 0, 0])\n",
        "            image = outline(image, y_true[s, 0], color=[0, 255, 0])\n",
        "            filename = \"{}-{}.png\".format(p, str(s).zfill(2))\n",
        "            filepath = os.path.join(\"./predictions\", filename)\n",
        "            imsave(filepath, image)"
      ],
      "metadata": {
        "id": "2vquaAK63hlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prediction結果を表示 ###"
      ],
      "metadata": {
        "id": "EIKSAedanJ3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction結果を表示\n",
        "images = [Image.open(img) for img in glob.glob(\"./predictions/*\")[0:30]]\n",
        "\n",
        "cols =3\n",
        "rows = len(images)//cols+1 #縦の行\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(cols*5, rows*5))\n",
        "\n",
        "\n",
        "for i, im in enumerate(images):\n",
        "    fig.add_subplot(rows, cols, i+1).set_title(str(i+1))\n",
        "    plt.imshow(im)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ELO1o_fybS4Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}